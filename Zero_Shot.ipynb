{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Zero Shot.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "3aqEu-mw0QoS",
        "z1aVymQa1mdD"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8904840bbc8745dc844f7e5228f14908": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_443c299d714a478f9a8a0eff61b6ace8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8cbe6bf778e345a8b3a2081f0ed5e04e",
              "IPY_MODEL_4cd69f7a8d4f491d910f492eada08fa7"
            ]
          }
        },
        "443c299d714a478f9a8a0eff61b6ace8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8cbe6bf778e345a8b3a2081f0ed5e04e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c3c11b0f0afa4d77a3e1ce35899b02ad",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 898823,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 898823,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ee5898af3c18447fb1d7101924492fdb"
          }
        },
        "4cd69f7a8d4f491d910f492eada08fa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1749e472c62a4aa7a231577df540809c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 899k/899k [00:01&lt;00:00, 676kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4c6d94e4fd7c4b8daa4bb72411ca5c7e"
          }
        },
        "c3c11b0f0afa4d77a3e1ce35899b02ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ee5898af3c18447fb1d7101924492fdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1749e472c62a4aa7a231577df540809c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4c6d94e4fd7c4b8daa4bb72411ca5c7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e2cb425e759841408b368a9f0daecfd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_968ec17e333a406b8174bb102eb071f7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f9dd291a0581462685be5bbc4d1bc9b8",
              "IPY_MODEL_47e3683f8cdf4133bdcd2323038543db"
            ]
          }
        },
        "968ec17e333a406b8174bb102eb071f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f9dd291a0581462685be5bbc4d1bc9b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2c1bd31615ad45dd95a6b809827d1d50",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4da23c3a3a2e46a598fe16cc0a775856"
          }
        },
        "47e3683f8cdf4133bdcd2323038543db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8d725720465a4a82a93269561bc12c5b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 901kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ec455b321c104e15b5bb7fa427cd1574"
          }
        },
        "2c1bd31615ad45dd95a6b809827d1d50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4da23c3a3a2e46a598fe16cc0a775856": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8d725720465a4a82a93269561bc12c5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ec455b321c104e15b5bb7fa427cd1574": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2bc94607eddd4e4ead266b82b00a8b40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_49bdeb597505432bb79d8eac9bc42846",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8c1b664efaf9472d837e9a9197aadf34",
              "IPY_MODEL_f1296e3c66a14eb3a6137f693cea7357"
            ]
          }
        },
        "49bdeb597505432bb79d8eac9bc42846": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8c1b664efaf9472d837e9a9197aadf34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c0f1e8a26a6a4e64822cea4bfde86d98",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 908,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 908,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_89a95780a48d4e12a92be4529fd58b09"
          }
        },
        "f1296e3c66a14eb3a6137f693cea7357": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_36b46e64a76b4e0488e2bf71fd260d79",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 908/908 [00:00&lt;00:00, 1.26kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_800a0d1b5c5841209c2c6352ba887296"
          }
        },
        "c0f1e8a26a6a4e64822cea4bfde86d98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "89a95780a48d4e12a92be4529fd58b09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "36b46e64a76b4e0488e2bf71fd260d79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "800a0d1b5c5841209c2c6352ba887296": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eff8e617e29f4a12af0d87577fa39b1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3a8fb47dd60348f08cc750c83bf09ab3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c5ed342261f64a96a6ab8bc2ad6846af",
              "IPY_MODEL_685c60f822c14fa59f07df64a4b46553"
            ]
          }
        },
        "3a8fb47dd60348f08cc750c83bf09ab3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c5ed342261f64a96a6ab8bc2ad6846af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4200c71e62214ad59faeac3e51e338e6",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1629486723,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1629486723,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8050f29d25e74a399836813ad9da464c"
          }
        },
        "685c60f822c14fa59f07df64a4b46553": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e331ca57f7354eb799ce87d107f7fb79",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.63G/1.63G [00:36&lt;00:00, 44.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bde0ecfc0cb6472db0d8a8ebba246894"
          }
        },
        "4200c71e62214ad59faeac3e51e338e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8050f29d25e74a399836813ad9da464c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e331ca57f7354eb799ce87d107f7fb79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bde0ecfc0cb6472db0d8a8ebba246894": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fshivam/Semantic-Video-Recommender-System/blob/master/Zero_Shot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjeHMqL15_AY",
        "colab_type": "text"
      },
      "source": [
        "# **This notebook is addressed to Dr. Parul Shah and is to be considered alongside the draft of the approach proposed regarding the Sadhguru NLP Project discussed.**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "We recommend this notebook be run on a GPU runtime by:\n",
        "\n",
        "**`Runtime -> Change Runtime Type -> Hardware Accelerator -> GPU -> Save`**\n",
        "\n",
        "*Note: The notebook is compatible with CPU runtimes too with no changes to the code.*\n",
        "\n",
        "*Note: The runtime will have to be restarted for some specific libraries to be able to function as per expectation by:* **`Runtime -> Restart Runtime`**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEWgVnxl6Fo6",
        "colab_type": "text"
      },
      "source": [
        "## **Install required libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Om13vRJ-6Igj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e72f6ae7-0eec-4086-baee-8c663f42dfc7"
      },
      "source": [
        "!pip3 install -q SpeechRecognition\n",
        "!pip3 install -q youtube-dl  \n",
        "!pip3 install -q pydub\n",
        "!pip3 install -q youtube_transcript_api\n",
        "!python -m spacy download en_core_web_lg\n",
        "!pip3 install -q pytube3\n",
        "!pip3 install -q pyspellchecker\n",
        "!pip install -q --upgrade google-api-python-client\n",
        "!pip install -q --upgrade google-auth-oauthlib google-auth-httplib2\n",
        "!pip install -U sentence-transformers\n",
        "!pip3 install -q transformers==2.11.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32.8MB 92kB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.8MB 4.5MB/s \n",
            "\u001b[?25hCollecting en_core_web_lg==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz (827.9MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 827.9MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_lg==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.7.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (47.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.6.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.1.0)\n",
            "Building wheels for collected packages: en-core-web-lg\n",
            "  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-lg: filename=en_core_web_lg-2.2.5-cp36-none-any.whl size=829180944 sha256=eb156ce24e8306ce96daab6c8b1ff60271c6bc95971a188e8cf76579d240aafe\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ct40_ebg/wheels/2a/c1/a6/fc7a877b1efca9bc6a089d6f506f16d3868408f9ff89f8dbfc\n",
            "Successfully built en-core-web-lg\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-2.2.5\n",
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.9MB 4.5MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61kB 2.8MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92kB 7.1MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.3MB 16.3MB/s \n",
            "\u001b[31mERROR: google-api-core 1.21.0 has requirement google-auth<2.0dev,>=1.18.0, but you'll have google-auth 1.17.2 which is incompatible.\u001b[0m\n",
            "\u001b[?25hCollecting sentence-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/47/0ed64014af68aaf36f2e0a42bb30a5caf82e54edf92329d8aca4959ba9d7/sentence-transformers-0.2.6.2.tar.gz (60kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61kB 3.0MB/s \n",
            "\u001b[?25hCollecting transformers==2.11.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/35/ad2c5b1b8f99feaaf9d7cdadaeef261f098c6e1a6a2935d4d07662a6b780/transformers-2.11.0-py3-none-any.whl (674kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 675kB 11.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.5.1+cu101)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: nltk in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0->sentence-transformers) (2.23.0)\n",
            "Collecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.8MB 13.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0->sentence-transformers) (20.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 59.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0->sentence-transformers) (0.7)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 57.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0->sentence-transformers) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.1->sentence-transformers) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sentence-transformers) (0.15.1)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from nltk->sentence-transformers) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.11.0->sentence-transformers) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.11.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.11.0->sentence-transformers) (2.9)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.11.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==2.11.0->sentence-transformers) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.11.0->sentence-transformers) (7.1.2)\n",
            "Building wheels for collected packages: sentence-transformers, sacremoses\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-0.2.6.2-cp36-none-any.whl size=79982 sha256=cdbe4eccb7851c8d5f53872bdd094a740ae13e74b8c241c895f00b617d83bf42\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/fc/be/8482e9a1e1313463bba5c9749e34657017afc251919d909321\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=53d5c54f83de0faea2f8801814f1d6ea3329a72c5c461e43579d31ec472033c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sentence-transformers sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers, sentence-transformers\n",
            "Successfully installed sacremoses-0.0.43 sentence-transformers-0.2.6.2 sentencepiece-0.1.91 tokenizers-0.7.0 transformers-2.11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15FFcJPK6PcS",
        "colab_type": "text"
      },
      "source": [
        "## **Import Required Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iux-xsFn6L-7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "d9030b30-7258-4c09-bfaa-4832bfc42335"
      },
      "source": [
        "import numpy as np\n",
        "import textwrap\n",
        "import urllib\n",
        "import json\n",
        "import spacy\n",
        "import en_core_web_lg\n",
        "import re\n",
        "import math \n",
        "import torch\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import os\n",
        "import google_auth_oauthlib.flow\n",
        "import googleapiclient.discovery\n",
        "import googleapiclient.errors\n",
        "import time\n",
        "import nltk\n",
        "\n",
        "\n",
        "from transformers import pipeline\n",
        "from transformers import BartForSequenceClassification, BartTokenizer\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "from urllib.parse import urlparse, parse_qs\n",
        "from spellchecker import SpellChecker \n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from pprint import pprint\n",
        "from dateutil import parser\n",
        "from nltk.tag import pos_tag\n",
        "from spellchecker import SpellChecker "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-a8d635ffec99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBartForSequenceClassification\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBartTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Configurations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconfiguration_albert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mALBERT_PRETRAINED_CONFIG_ARCHIVE_MAP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAlbertConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconfiguration_auto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mALL_PRETRAINED_CONFIG_ARCHIVE_MAP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCONFIG_MAPPING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconfiguration_bart\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBartConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/configuration_albert.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\"\"\" ALBERT model configuration \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconfiguration_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfile_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCONFIG_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhf_bucket_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_remote_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mUSE_TF\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ON\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"YES\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"AUTO\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mUSE_TORCH\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ON\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"YES\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__version__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary_pb2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattr_value_pb2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_graph_pb2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorInfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_graph_pb2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMetaGraphDef\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_pb2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/core/protobuf/meta_graph_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0many_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgoogle_dot_protobuf_dot_any__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgraph_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_graph__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mop_def_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_op__def__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/protobuf/any_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0msyntax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'proto3'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0mserialized_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mb'\\n\\023com.google.protobufB\\010AnyProtoP\\001Z%github.com/golang/protobuf/ptypes/any\\242\\002\\003GPB\\252\\002\\036Google.Protobuf.WellKnownTypes'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m   \u001b[0mcreate_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_descriptor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_create_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m   \u001b[0mserialized_pb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mb'\\n\\x19google/protobuf/any.proto\\x12\\x0fgoogle.protobuf\\\"&\\n\\x03\\x41ny\\x12\\x10\\n\\x08type_url\\x18\\x01 \\x01(\\t\\x12\\r\\n\\x05value\\x18\\x02 \\x01(\\x0c\\x42o\\n\\x13\\x63om.google.protobufB\\x08\\x41nyProtoP\\x01Z%github.com/golang/protobuf/ptypes/any\\xa2\\x02\\x03GPB\\xaa\\x02\\x1eGoogle.Protobuf.WellKnownTypesb\\x06proto3'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m )\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'google.protobuf.descriptor' has no attribute '_internal_create_key'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8g6rUXF6XKk",
        "colab_type": "text"
      },
      "source": [
        "## **Configure GPU for Accelerating Text Summarization Model**\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "Using a GPU helps us dramatically decrease the inference times of the BART model used for getitng summaries from video transcripts. This helps the program scale to thousands of transcripts.\n",
        "\n",
        "*Note: Ignore this cell if running on a CPU Runtime*\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSWSdQed6Tko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime â†’ \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
        "\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzKsOeGP6daH",
        "colab_type": "text"
      },
      "source": [
        "## **Define the AutoSynop Class**\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "The AutoSynop Class achieves the following things:\n",
        "\n",
        "\n",
        "\n",
        "1.  ` __init__()` : Defines API Keys (for accessing YouTube) and the Channel ID of the Sadhguru Channel used later. It also downloads the text summarization model.\n",
        "\n",
        "2.  `get_metadata_for_videos(playlists)`: Fetches metadata of all videos hosted under a given playlist for the given channel. \n",
        "\n",
        "3.  `scrap_duplicates(video_metadata)`: Sometimes, playlists have same videos uploaded under different video IDs, this method scraps them and keeps only the unique videos.\n",
        "\n",
        "4.  `get_video_ids_from_metadata(video_metadata)` : Extract only the video IDs from the video metadata obtained from `get_metadata_for_videos(playlists)` method.\n",
        "\n",
        "5. `get_transcripts(video_ids)`: Fetches the transcripts, timed version of the transcript (as it appears on the video screen) and the start and duration of each text in the video frame based on the extracted video IDs.\n",
        "\n",
        "6. `process_and_split_transcript()`: Split the transcript into uniform blocks of size approximately 250 (to avoid memory errors), get summaries for those blocks and combine the summaries into a single summary by simple concatenation.\n",
        "\n",
        "\n",
        "**Thus the final returned output of running the methods in this class are a list of summaries for the fetched transcripts**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbZnLXkS6aU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AutoSynop():\n",
        "\n",
        "  def __init__(self):\n",
        "\n",
        "    self.API_KEY = 'AIzaSyCHYJRuKOkaIFlU5FBKzYjrZli1CFvpxXg'\n",
        "    self.nlp = en_core_web_lg.load()\n",
        "    nltk.download('averaged_perceptron_tagger')\n",
        "    nltk.download('punkt')\n",
        "    self.summarizer = pipeline('summarization', device = 0)\n",
        "    self.wrapper = textwrap.TextWrapper(width=80) \n",
        "    \n",
        "\n",
        "  def get_metadata_for_videos(self, playlists):\n",
        "\n",
        "    # Helper Function 1\n",
        "    # Process the JSON response\n",
        "    def process_response(response):\n",
        "\n",
        "      next_page_flag = 1\n",
        "      video_ids = list()\n",
        "      titles = list()\n",
        "\n",
        "      items = response['items']\n",
        "\n",
        "      try:\n",
        "        nextPageToken = response['nextPageToken']\n",
        "\n",
        "      except KeyError:\n",
        "        next_page_flag = 0\n",
        "        #print('Reached end of playlist!')\n",
        "\n",
        "      for item in items:\n",
        "        video_id = item['contentDetails']['videoId']\n",
        "        title = item['snippet']['title']\n",
        "        video_ids.append(video_id)\n",
        "        titles.append(title)\n",
        "\n",
        "        #print(video_id)\n",
        "        #print(title)       \n",
        "\n",
        "      if next_page_flag==1:\n",
        "        return video_ids, titles, nextPageToken\n",
        "\n",
        "      if next_page_flag==0:\n",
        "        return video_ids, titles, None\n",
        "\n",
        "    # Helper Function 2\n",
        "    # Process to get video IDs and titles for all videos in one playlist\n",
        "    def get_video_ids_for_playlist(youtube, playlist_id, nextPageToken):\n",
        "\n",
        "      if nextPageToken==None:\n",
        "\n",
        "        request = youtube.playlistItems().list(\n",
        "            part=\"snippet, contentDetails\",\n",
        "            maxResults=50,\n",
        "            playlistId=playlist_id)\n",
        "        \n",
        "      if nextPageToken!=None:\n",
        "\n",
        "        request = youtube.playlistItems().list(\n",
        "          part=\"snippet, contentDetails\",\n",
        "          maxResults=50,\n",
        "          playlistId=playlist_id,\n",
        "          pageToken=nextPageToken)\n",
        "\n",
        "      response = request.execute()\n",
        "      \n",
        "      video_ids, titles, nextPageToken = process_response(response)\n",
        "\n",
        "      return video_ids, titles, nextPageToken\n",
        "\n",
        "\n",
        "    # Main function starts here\n",
        "\n",
        "    # Set up a YouTube API Client\n",
        "    api_service_name = \"youtube\"\n",
        "    api_version = \"v3\"\n",
        "\n",
        "    youtube = googleapiclient.discovery.build(\n",
        "        api_service_name, \n",
        "        api_version, \n",
        "        developerKey=self.API_KEY)\n",
        "    \n",
        "    # Iterate over all playlists and fetch video IDs for ALL playlists\n",
        "    for idx, playlist in enumerate(tqdm((playlists))):\n",
        "\n",
        "      playlist_video_ids = list()\n",
        "      playlist_titles = list()\n",
        "\n",
        "      playlist_id = playlist[playlist.find('&list=')+6:]\n",
        "\n",
        "      #print(playlist_id)\n",
        "\n",
        "      video_ids, titles, nextPageToken = get_video_ids_for_playlist(youtube, playlist_id, None)\n",
        "      playlist_video_ids.extend(video_ids)\n",
        "      playlist_titles.extend(titles)\n",
        "\n",
        "      while nextPageToken!=None:\n",
        "\n",
        "        video_ids, titles, nextPageToken = get_video_ids_for_playlist(youtube, playlist_id, nextPageToken)\n",
        "        playlist_video_ids.extend(video_ids)\n",
        "        playlist_titles.extend(titles)\n",
        "      \n",
        "      #print('Processed a Playlist')\n",
        "      yield list(zip(playlist_video_ids, playlist_titles))\n",
        "    \n",
        "    print('All playlists done')\n",
        "\n",
        "\n",
        "  def scrap_duplicates(self, video_metadata):\n",
        "\n",
        "    all_video_ids_and_titles = {}\n",
        "\n",
        "    for p_num in range(len(video_metadata)):\n",
        "\n",
        "      playlist_metadata = dict(video_metadata[p_num])\n",
        "\n",
        "      cleaned_playlist_metadata = {}\n",
        "\n",
        "      for key,value in playlist_metadata.items():\n",
        "          if value not in cleaned_playlist_metadata.values():\n",
        "              cleaned_playlist_metadata[key] = value\n",
        "\n",
        "      all_video_ids_and_titles.update(cleaned_playlist_metadata)\n",
        "\n",
        "    cleaned_metadata = {}\n",
        "\n",
        "    for key,value in all_video_ids_and_titles.items():\n",
        "          if value not in cleaned_metadata.values():\n",
        "              cleaned_metadata[key] = value\n",
        "\n",
        "    return cleaned_metadata\n",
        "\n",
        "  def get_video_ids(self, cleaned_metadata):\n",
        "\n",
        "    return list(cleaned_metadata.keys())\n",
        "  \n",
        "  def get_video_titles(self, cleaned_metadata):\n",
        "\n",
        "    return list(cleaned_metadata.values())\n",
        "\n",
        "  def get_transcripts(self, cleaned_metadata):\n",
        "\n",
        "    video_ids = list(cleaned_metadata.keys())\n",
        "\n",
        "    transcripts = list()\n",
        "    timed_transcripts = list()\n",
        "    chrono_of_timed_transcripts = list()\n",
        "    failed_video_ids = list()\n",
        "\n",
        "    fail = 0\n",
        "    success = 0\n",
        "    total = 0\n",
        "\n",
        "    for video_id in tqdm(video_ids, position=0):\n",
        "\n",
        "      total += 1\n",
        "\n",
        "      try:\n",
        "        dict_responses = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "        transcript = ' '.join([response['text'] for response in dict_responses])\n",
        "        timed_transcript = [response['text'] for response in dict_responses]\n",
        "        chrono_of_timed_transcript = [response['start'] + response['duration'] for response in dict_responses]\n",
        "        transcripts.append(transcript)\n",
        "        timed_transcripts.append(timed_transcript)\n",
        "        chrono_of_timed_transcripts.append(chrono_of_timed_transcript)\n",
        "        success += 1\n",
        "        \n",
        "      except Exception as e: \n",
        "        print(e)\n",
        "        failed_video_ids.append(video_id)\n",
        "        print(video_id)\n",
        "        fail += 1\n",
        "        continue\n",
        "  \n",
        "      print('{} of {} videos done and {} failed until now'.format(success, total, fail))\n",
        "      time.sleep(8)\n",
        "    \n",
        "    cleaned_metadata = {key:value for key, value in cleaned_metadata.items() if key not in failed_video_ids}\n",
        "  \n",
        "    print('Number of transcripts retrieved: {}'.format(len(transcripts)))\n",
        "\n",
        "    assert len(transcripts) == len(timed_transcripts)\n",
        "    assert len(timed_transcripts) == len(chrono_of_timed_transcripts)\n",
        "\n",
        "    return transcripts, timed_transcripts, chrono_of_timed_transcripts, cleaned_metadata\n",
        "\n",
        "\n",
        "  def process_and_split_transcript(self, transcripts, timed_transcripts, chrono_of_timed_transcripts):\n",
        "\n",
        "    # Helper Fuction 1 \n",
        "    # To get blocks lengths\n",
        "    def get_blocks_lengths(blocks):\n",
        "\n",
        "      len_blocks = list()\n",
        "\n",
        "      for idx, block in enumerate(blocks):\n",
        "\n",
        "        block_text = ' '.join([sent for sent in block[0]])\n",
        "        length = sum([len(sent.strip().split()) for sent in block[0]])\n",
        "        len_blocks.append((idx, length))\n",
        "        #print('BLOCK: {}'.format(idx+1))\n",
        "        #print('\\n')\n",
        "        #print(wrapper.fill(block_text))\n",
        "        #print('\\n')\n",
        "        #print('LENGTH OF BLOCK: {} is {}'.format(idx+1,length ))\n",
        "        #print('\\n')\n",
        "        #print('-' * 100)\n",
        "        #print('\\n')\n",
        "\n",
        "      return len_blocks\n",
        "\n",
        "\n",
        "    # Helper Function 2\n",
        "    # To print summaries for individual blocks in a transcript\n",
        "    # In addition, also return the combined summary by adding all blocks\n",
        "    def distil_block(blocks):\n",
        "\n",
        "      block_summaries = list()\n",
        "\n",
        "      for idx, block in enumerate(blocks):\n",
        "        block_text = ' '.join([sent for sent in block[0]])\n",
        "        block_summary = self.summarizer(block_text)[0]['summary_text']\n",
        "        #print('SUMMARY OF BLOCK: {}'.format(idx+1))\n",
        "        #print('\\n')\n",
        "        #print(wrapper.fill(block_summary))\n",
        "        #print('-' * 100)\n",
        "        #print('\\n')\n",
        "        block_summaries.append(block_summary)\n",
        "\n",
        "\n",
        "      return block_summaries\n",
        "\n",
        "\n",
        "    # Helper Function 3\n",
        "    # Clean up text with regex\n",
        "    def clean_up(transcript, timed_transcript):\n",
        "\n",
        "      # Clean up transcript\n",
        "      transcript = re.sub('(\\\\n)', ' ', transcript)\n",
        "      transcript = re.sub('(\\.\\.+)', '', transcript)\n",
        "      transcript = re.sub('\\s+', ' ', transcript)\n",
        "\n",
        "      # Clean up timed captions from JSON response\n",
        "      timed_transcript = [re.sub('(\\\\n)', ' ', sentence) for sentence in timed_transcript]\n",
        "      timed_transcript = [re.sub('(\\.\\.+)', '', sentence) for sentence in timed_transcript]\n",
        "      timed_transcript = [re.sub('\\s+', ' ', sentence) for sentence in timed_transcript]\n",
        "      \n",
        "\n",
        "      return transcript, timed_transcript\n",
        "  \n",
        "    # Main function starts here\n",
        "\n",
        "    # Define empty lists to hold summaries and transcripts (with blocks and their timings)\n",
        "    summaries = list()\n",
        "    transcript_with_blocks_and_their_timings = list()\n",
        "    counter = 0\n",
        "\n",
        "    # Loop over all transcripts in the database\n",
        "    for (transcript, timed_transcript, chrono_of_timed_transcript) in tqdm(zip(transcripts, timed_transcripts, chrono_of_timed_transcripts), total=len(timed_transcripts)):\n",
        "\n",
        "      # Clean up all text\n",
        "      transcript, timed_transcript = clean_up(transcript, timed_transcript)\n",
        "\n",
        "      # Ensure lengths of transcripts and timed transcripts after cleaning is the same\n",
        "      length_of_transcript = len(transcript.strip().split())\n",
        "      length_of_timed_transcript = sum([len(sentence.strip().split()) for sentence in timed_transcript])\n",
        "      assert length_of_timed_transcript == length_of_transcript\n",
        "\n",
        "\n",
        "      # Calculate number of blocks and the allowed margin\n",
        "      num_blocks = math.ceil(length_of_timed_transcript/250)\n",
        "      allowed_margin = sum([len(sent.strip().split()) for sent in timed_transcript])/len(timed_transcript)\n",
        "      #print('Allowed margin is {}'.format(allowed_margin))\n",
        "      #print('Number of blocks are: {}'.format(num_blocks))\n",
        "\n",
        "      try:\n",
        "        length_of_each_block = math.floor(length_of_timed_transcript/num_blocks)\n",
        "        #print('Length of each block is {}'.format(length_of_each_block))\n",
        "      except ZeroDivisionError:\n",
        "        #print('\\n')\n",
        "        #print('Removing a very short transcript (<100 words)')\n",
        "        continue\n",
        "\n",
        "      # Define some more variables to hold miscellaneous intermediates\n",
        "      block=list()\n",
        "      buffer = str()\n",
        "      blocks = list()\n",
        "      block_length = 0\n",
        "      flag = 0\n",
        "      sentences_proccessed = 0\n",
        "\n",
        "      # Iterate over all sentences in the transcript to divide it into roughly equal blocks\n",
        "\n",
        "      for idx, sentence in enumerate(timed_transcript):\n",
        "\n",
        "        if flag==0:\n",
        "          pass\n",
        "\n",
        "        if flag==1:\n",
        "          assert block_length==0\n",
        "          block.append(buffer)\n",
        "          block_length += len(buffer.strip().split())\n",
        "          flag = 0\n",
        "\n",
        "        length_of_current_sentence = len(sentence.strip().split())\n",
        "        block_length += length_of_current_sentence\n",
        "        #print('Length of block currently is at: {}'.format(block_length))\n",
        "          \n",
        "\n",
        "        if block_length < length_of_each_block and block_length + allowed_margin <= length_of_each_block:\n",
        "          block.append(sentence)\n",
        "          sentences_proccessed+=1\n",
        "        \n",
        "        elif block_length == length_of_each_block:\n",
        "          block.append(sentence)\n",
        "          sentences_proccessed+=1\n",
        "          \n",
        "        else:\n",
        "          flag = 1\n",
        "          buffer = sentence\n",
        "          sentences_proccessed+=1\n",
        "          #print(block)\n",
        "          #print((block, idx))\n",
        "          blocks.append((block, idx-1))\n",
        "          #print(blocks)\n",
        "          block_length = 0\n",
        "          block=list()\n",
        "\n",
        "      # Ensure there is at least 1 block\n",
        "      if len(blocks)==0:\n",
        "        blocks.append((block, idx))\n",
        "        block_length = 0\n",
        "        block=list()\n",
        "\n",
        "      # Handle the case when there are some sentences that missed out\n",
        "      if len(block)!=0:\n",
        "\n",
        "        # Get last block\n",
        "        for left_over_sent in block:\n",
        "          blocks[-1][0].append(left_over_sent)\n",
        "\n",
        "\n",
        "      # Ensure all sentences in the transcript have been processed once and only once\n",
        "      assert sentences_proccessed == len(timed_transcript)\n",
        "\n",
        "      # Get blocks with their lengths\n",
        "      len_blocks = get_blocks_lengths(blocks)\n",
        "\n",
        "      # Get end timings for each block in transcript \n",
        "      end_timing_of_blocks = [chrono_of_timed_transcript[-1] if idx+1==len(blocks) else chrono_of_timed_transcript[block[1]] for idx, block in enumerate(blocks)]\n",
        "\n",
        "      # Store transcripts, with all its blocks and their timings for targeted search\n",
        "      transcript_with_blocks_and_their_timings.append((transcript, blocks, end_timing_of_blocks))\n",
        "\n",
        "      # Summarize individual blocks\n",
        "      summary_blocks = distil_block(blocks)\n",
        "\n",
        "      # Replace multiple spaces in the summary blocks with a single space\n",
        "      summary_blocks = [re.sub('\\s+', ' ', summary_block) for summary_block in summary_blocks]\n",
        "\n",
        "      # Append the summary to the 'summaries' list\n",
        "      summaries.append(summary_blocks)\n",
        "\n",
        "    return summaries, transcript_with_blocks_and_their_timings\n",
        "\n",
        "\n",
        "  # There is no point in generating a 'summary' for a very short transcript (<100 words)\n",
        "  # Hence, we fill those NaN values in the summaries by the corresponding transcripts themselves\n",
        "  # THIS FUNCTION IS UNDER DEVELOPMENT, DO NOT CALL\n",
        "  def fill_nans(self, summaries, transcripts):\n",
        "\n",
        "    empty = list()\n",
        "\n",
        "    for idx, summary in enumerate(summaries):\n",
        "\n",
        "      if not summary:\n",
        "        empty.append(idx)\n",
        "\n",
        "    for idx in empty:\n",
        "\n",
        "      summaries[idx] = transcripts[idx]\n",
        "\n",
        "    for summary in summaries:\n",
        "    \n",
        "      assert len(summary.strip().split()) != 0\n",
        "\n",
        "    print('Successfully Copied over the transcripts as it is to summaries where the length was less than 100 words!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUq1WWu_oqHj",
        "colab_type": "text"
      },
      "source": [
        "## **Use AutoSynop Class to get Automated Synopses**\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "We will first define playlists (their links) and their names taken from the official Sadhguru public channel on YouTube. \n",
        "\n",
        "Next, we will use the AutoSynop Class (and its methods) to obtain a database of summaries for ~850 transcripts in an end-to-end fashion\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u25bhs4jonbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First, let us define our playlists\n",
        "# It is from these playlists that we will be downloading transcripts\n",
        "\n",
        "playlists = '''\n",
        "\n",
        "https://www.youtube.com/watch?v=Dl8MUnLfEsk&list=PL3uDtbb3OvDOWpCZ8ERCXHMcslGaBEOBT\n",
        "https://www.youtube.com/watch?v=cxoQdEhHaT8&list=PL3uDtbb3OvDNXmmy_3Q7SCHIZdz9ja4SG\n",
        "https://www.youtube.com/watch?v=yL_fgyXXnSM&list=PL3uDtbb3OvDPHh7DWhekbw-ywA7SCnstr\n",
        "https://www.youtube.com/watch?v=O1B0lDS1Jnw&list=PL3uDtbb3OvDNsDLMnmyR94MTfGHQh6HtP\n",
        "https://www.youtube.com/watch?v=zO8QzMWZbN4&list=PL3uDtbb3OvDMpNqWoWfsY9qqT7UZijw0w\n",
        "https://www.youtube.com/watch?v=4OBLAW7oQYo&list=PL3uDtbb3OvDPup8tDy1viWElFkPZcL4pM\n",
        "https://www.youtube.com/watch?v=GM0lU5Dq7eA&list=PL3uDtbb3OvDPZG2coablWM-9XX6JQtSQT\n",
        "https://www.youtube.com/watch?v=vvntRXe6YcU&list=PL3uDtbb3OvDPBGzSYKBeEFlrG48_0DBC4\n",
        "https://www.youtube.com/watch?v=DTWMwHtF-UA&list=PL3uDtbb3OvDNnH5j_UFzZwR2KWg4TShJn\n",
        "https://www.youtube.com/watch?v=kAMvYHqTWs0&list=PL3uDtbb3OvDPt8Ayn5QQ_13Juo98-EDxP\n",
        "https://www.youtube.com/watch?v=xswUGZOVdc4&list=PL3uDtbb3OvDPLLMGlDi3C3-uAwyTBXtnR\n",
        "https://www.youtube.com/watch?v=3J-cYxxHQGQ&list=PL3uDtbb3OvDNxpFp3baiPKRM4tGtD3_Me\n",
        "https://www.youtube.com/watch?v=f7-lwz_FacE&list=PL3uDtbb3OvDMjs6pYa27tCweTBKBgxUij\n",
        "https://www.youtube.com/watch?v=a6danRWYxpo&list=PL3uDtbb3OvDNVQJSz1__CuW-IS2s2kw2A\n",
        "https://www.youtube.com/watch?v=uoIXz3KcwME&list=PL3uDtbb3OvDMgLTgfZe4fDN48SYfEtesX\n",
        "https://www.youtube.com/watch?v=bJggjXvB52c&list=PL3uDtbb3OvDMHDwKA8sPrEi2SV3IKnT0S\n",
        "https://www.youtube.com/watch?v=4OBLAW7oQYo&list=PL3uDtbb3OvDPAcaMIq68euWqHvZosh8JI\n",
        "https://www.youtube.com/watch?v=QAsJvKsd2Xk&list=PL3uDtbb3OvDNWKnzD4MJRQRX_wBAT9iDC\n",
        "https://www.youtube.com/watch?v=UT_nWVLi4Ws&list=PL3uDtbb3OvDMMbCg-hvVjXYZ3osM4rpr2\n",
        "https://www.youtube.com/watch?v=X_fHa73_nOg&list=PL3uDtbb3OvDNo0TvQIHbB6TLndA7jEMTR\n",
        "https://www.youtube.com/watch?v=HIkgY0Rz1jU&list=PL3uDtbb3OvDMaNezBWgE_SNQ6QkeYkV1w\n",
        "https://www.youtube.com/watch?v=AHS1c_vqjxI&list=PL3uDtbb3OvDMBO-NUpWCvV_zhJh1pFlEX\n",
        "https://www.youtube.com/watch?v=diFkCJ802vY&list=PL3uDtbb3OvDMdjRscdox0QYkcE9cghmvx\n",
        "https://www.youtube.com/watch?v=rbYdXbEVm6E&list=PL3uDtbb3OvDONMcvq4e82gs33laM4IJ_z\n",
        "https://www.youtube.com/watch?v=235gIzWOkrM&list=PL3uDtbb3OvDNDjm-mp82KCJB6VDpqZi3I\n",
        "\n",
        "'''\n",
        "\n",
        "playlists = playlists.strip().split('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbZoRXf-pYqE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Next, let's create an object of the class\n",
        "Autosynop = AutoSynop()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSDdSRjzpas3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get video IDs of all videos in the playlists\n",
        "\n",
        "# First we obtain the video metadata which includes the video ID and the title\n",
        "# We will do this using the get_metadata_for_videos() method\n",
        "video_metadata = list(Autosynop.get_metadata_for_videos(playlists))\n",
        "\n",
        "\n",
        "# We will remove duplicate videos (if any) using the scrap_duplicates() method\n",
        "# This will rid the video metadata of any duplicacies\n",
        "cleaned_metadata = Autosynop.scrap_duplicates(video_metadata)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnaKTy1VqaKf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get transcripts along with timing metadata for those video ids\n",
        "# The timing metadata is used for targeted search (demonstrated later)\n",
        "\n",
        "# If files are not provided, run this\n",
        "#transcripts, timed_transcripts, chrono_of_timed_transcripts, cleaned_metadata = Autosynop.get_transcripts(cleaned_metadata)\n",
        "\n",
        "# Finally, we'll seperate out our video IDs from the cleaned video metadata\n",
        "# This is done using the get_video_ids() and get_video_titles() method\n",
        "# If files are not provided, run this\n",
        "#video_ids = Autosynop.get_video_ids(cleaned_metadata)\n",
        "#video_titles = Autosynop.get_video_titles(cleaned_metadata)\n",
        "\n",
        "# If files already provided, run this instead\n",
        "with open('/content/transcripts_f.pickle', 'rb') as handle:\n",
        "    transcripts = pickle.load(handle)\n",
        "\n",
        "with open('/content/timed_transcripts_f.pickle', 'rb') as handle:\n",
        "    timed_transcripts = pickle.load(handle)\n",
        "\n",
        "\n",
        "with open('/content/chrono_of_timed_transcripts_f.pickle', 'rb') as handle:\n",
        "    chrono_of_timed_transcripts = pickle.load(handle)\n",
        "\n",
        "\n",
        "with open('/content/cleaned_metadata_f.pickle', 'rb') as handle:\n",
        "    cleaned_metadata = pickle.load(handle)\n",
        "\n",
        "\n",
        "with open('/content/video_ids_f.pickle', 'rb') as handle:\n",
        "    video_ids = pickle.load(handle)\n",
        "\n",
        "\n",
        "with open('/content/video_titles_f.pickle', 'rb') as handle:\n",
        "    video_titles = pickle.load(handle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oynOJdsIqxP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Finally, get summaries for all transcripts\n",
        "# Also, get the start and end times of the blocks in the transcript (used for targeted search, demonstrated later)\n",
        "# This will take a while to execute ~2.5 hours on a P100 - PCE GPU \n",
        "# summaries, transcript_with_blocks_and_their_timings = Autosynop.process_and_split_transcript(transcripts, timed_transcripts, chrono_of_timed_transcripts)\n",
        "\n",
        "# If files are provided, run this instead \n",
        "with open('/content/transcript_with_blocks_and_their_timings_f.pickle', 'rb') as handle:\n",
        "  transcript_with_blocks_and_their_timings = pickle.load(handle)\n",
        "\n",
        "with open('/content/summaries_f.pickle', 'rb') as handle:\n",
        "    summaries = pickle.load(handle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hvXKrT0rc-P",
        "colab_type": "text"
      },
      "source": [
        "## **Save the Summaries to a Pandas DataFrame for Recommendation**\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "The saved DataFrame has four columns:\n",
        "\n",
        "\n",
        "1.   Video ID\n",
        "2.   Video Title\n",
        "3.   Summary\n",
        "4.   Summary Blocks\n",
        "5.   Summary Block End Timings\n",
        "6.   Length of Summary\n",
        "7.   Transcript\n",
        "8.   Transcript Blocks\n",
        "9.   Transcript Block End Timings\n",
        "10.   Length of Transcript\n",
        "\n",
        "\n",
        "**The .csv file is saved at path:**\n",
        "\n",
        "`/content/db_633.pickle`\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ewoEbF_rsQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_df(video_ids, video_titles, summaries, transcripts, transcript_with_blocks_and_their_timings):\n",
        "\n",
        "  joined_summaries = [' '.join(summary_block) for summary_block in summaries]\n",
        "  length_transcripts = [len(transcript.strip().split()) for transcript in transcripts]\n",
        "  length_summaries = [len(summary.strip().split()) for summary in joined_summaries]\n",
        "  transcripts = [element[0] for element in transcript_with_blocks_and_their_timings]\n",
        "  transcript_blocks = [element[1] for element in transcript_with_blocks_and_their_timings]\n",
        "  block_end_timings = [element[2] for element in transcript_with_blocks_and_their_timings]\n",
        " \n",
        "\n",
        "  tuples_for_df = list(zip(video_ids, video_titles, joined_summaries, summaries, block_end_timings, length_summaries, transcripts, transcript_blocks, block_end_timings, length_transcripts))\n",
        "  df = pd.DataFrame(tuples_for_df, columns = ['Video ID', 'Video Title', 'Summary', 'Summary Blocks', 'Summary Block End Timings', 'Length of Summary',  'Transcript', 'Transcript Blocks', 'Transcript Block End Timings',  'Length of Transcript'])\n",
        "  df.to_pickle('/content/db_633_f.pickle')\n",
        "\n",
        "  return df \n",
        "\n",
        "df = save_df(video_ids, video_titles, summaries, transcripts, transcript_with_blocks_and_their_timings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHD27mJs8JZV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preview the dataframe\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HTNvbi1svy_",
        "colab_type": "text"
      },
      "source": [
        "## **Matching using Zero Shot Classification**\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "The goal is to recommend the most relevant video from the database to the user based on a short description given by the user.\n",
        "\n",
        "Specifically, the inputs taken is:\n",
        "\n",
        "*   A brief description of the user's quandary or what he/she needs clarity on. \n",
        "\n",
        "\n",
        "Given this input, the proposed approach is as follows:\n",
        "\n",
        "\n",
        "1.   **Classify Summaries:** Even before the user input, we use Zero Shot Classification using Bart (Facebook AI) to classify all the summaries in the database as the probability that the summary belongs to each of the themes (defined in the beginning).\n",
        "\n",
        "\n",
        "2.   **Shortlist**: This step, involves two tracks of computation. First, we take the user input (as defined above) and next, we follow the following two tracks:\n",
        "\n",
        "\n",
        "*   **Track 1 (NLP on Video Titles):**\n",
        "    \n",
        "    This involves calculating embeddings for the user's input using roBERTa (Facebook AI) and the titles of the videos in the database. We use cosine distance in the embedding space between the user's input embeddings and the video title embeddings as a measure of similarity and shortlist the top 20 matched videos. We believe that there is a great deal of accurate semantic information in the title of the video itself and it should taken into consideration.\n",
        "\n",
        "*   **Track 2 (NLP on Summaries):**\n",
        "\n",
        "    First, we tag the user input using the concept of Zero Shot classify with Bart (Facebook AI). \n",
        "    \n",
        "    For example, a user's input could be:\n",
        "\n",
        "        \"I just had a breakup with my girlfriend. \n",
        "        She decided to part ways but I am unable to accept or process this. \n",
        "        I feel lost all the time and cannot focus at work or anywhere else. I cannot move on. \n",
        "        At night, her memory keeps me up. In the morning too, and even at work, I see her face. \n",
        "        I cannot get her out of my mind. I don't know what to do.\"\n",
        "\n",
        "    And the tags (using Zero Shot classification) would be:\n",
        "\n",
        "        [ 'love and relationships', 'suffering', 'stress' ]\n",
        "    \n",
        "    Next, we filter videos based on those tags (from our already Zero Shot classified database.)\n",
        "    \n",
        "    And finally, we calculate the cosine similarity between the embeddings of summaries of the filtered videos and the embeddings of the user input, selecting the top 20 here too.\n",
        "\n",
        "3.   **Recommendation**: In this next step, we take the intersection of Track 1 and Track 2, to end up with a list of videos that are very likely highly relevant to the user. The final list of videos are shown as recommendations. \n",
        "\n",
        "\n",
        "4.  **Smart Snippets (Targeted Recommendations)**: This takes the final list of recommendations and tries to find the best entry and exit points in the video and recommend them too. This is done by doing a transcript search, proceeding block by block and noting the times of the blocks in the transcripts that best fit the user's description. \n",
        "\n",
        "Each of the 4 steps, are documented below with code.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvsZF61c4jTV",
        "colab_type": "text"
      },
      "source": [
        "### **1.  Classify Summaries**\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "For each summary, the probability that the summary belongs to each theme is calculated in three ways using Bart (Facebook AI):\n",
        "\n",
        "1.   **Averaging**: In this method, for each summary, we zero shot classify *each block* of the summary as the probability that it belongs each of the themes, and then average those probabilites across all the summary blocks to return the final average probabilities. \n",
        "\n",
        "\n",
        "2.   **Soft Dominance**: In this method, for each summary, we zero shot classify *each block* of the summary as the probability that it belongs to each of the themes, and for *each summary block*, the most probable theme is found.The final probabilites are then calculated as: `number of times a theme has dominated a block (been the maximum) / number of blocks in the summary`\n",
        "\n",
        "\n",
        "3.   **Hard Dominance**: In this method, for each summary, we zero shot classify *each block* of the summary as the probability that it belongs each of the themes ans then for *each summary block*, the most probable theme is found *over a cummulative addition of probabilties*. The final probabilites are then calculated as: `number of times a theme has dominated the cummulative probability across blocks (been the maximum in cummulative probability across blocks) / number of blocks in the summary`\n",
        "\n",
        "We divide by `number of blocks in the summary` in all methods to keep the probabilities between 0 and 1 (as they should be)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7JWvSTjsrnv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First, we'll define the themes we'll be using to classify the transcripts on\n",
        "# These themes reflect the names of the playlists we have scrapped for the transcripts\n",
        "\n",
        "themes = '''\n",
        "\n",
        "love and relationships\n",
        "addiction and compulsiveness\n",
        "unraveling death\n",
        "karma\n",
        "education\n",
        "parenting\n",
        "suffering\n",
        "stress\n",
        "time management\n",
        "existence of god\n",
        "living happily\n",
        "health\n",
        "success\n",
        "depression\n",
        "marriage\n",
        "sleep and restfulness\n",
        "peace\n",
        "virus\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kjnu2dlY6PRi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Process themes and define a dict to map from the index number to the theme\n",
        "themes = themes.strip().split('\\n')\n",
        "emotion_list = themes\n",
        "emotion_ids = list(range(1, len(emotion_list)+1))\n",
        "emotion_ids_to_emotions = dict(zip(emotion_ids, emotion_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xm5PstOj3dZr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If df_633_f is provided, run this\n",
        "#summaries = df['Summary Blocks'].tolist()\n",
        "\n",
        "# If summaries_f.pkl is provided, run this\n",
        "with open('/content/summaries_f.pickle', 'rb') as handle:\n",
        "    summaries = pickle.load(handle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5unUSIh3_Oc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First, set up Bart\n",
        "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-mnli')\n",
        "model = BartForSequenceClassification.from_pretrained('facebook/bart-large-mnli')\n",
        "\n",
        "# Send the model to GPU and print out the architecture\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acje_qGj4LL5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Perform Zero Shot Classification\n",
        "\n",
        "# Setup logging and wrapped printing\n",
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "wrapper = textwrap.TextWrapper(width=80) \n",
        "\n",
        "# Define global list for Averaged method\n",
        "zero_shot_averaged = list()\n",
        "\n",
        "# Define global list for Hard Dominance method\n",
        "zero_shot_hard_dominance = list()\n",
        "\n",
        "# Define global list for Soft Dominance method\n",
        "zero_shot_soft_dominance = list()\n",
        "\n",
        "\n",
        "# Loop over all summaries\n",
        "for summary in tqdm(summaries):\n",
        "\n",
        "  initial_probs = [0.00] * len(emotion_list)\n",
        "  initial_dominance = [0] * len(emotion_list)\n",
        "  num_blocks = len(summary)\n",
        "  labels = emotion_list\n",
        "\n",
        "  # Define local list (one summary) for Averaged method\n",
        "  zero_shot_for_summary_averaged = dict(zip(emotion_list, initial_probs))\n",
        "\n",
        "  # Define local list (one summary) for Hard Dominance method\n",
        "  zero_shot_for_summary_hard_dominance = dict(zip(emotion_list, initial_dominance))\n",
        "\n",
        "  # Define local list (one summary) for Soft Dominance method\n",
        "  zero_shot_for_summary_soft_dominance = dict(zip(emotion_list, initial_dominance))\n",
        "\n",
        "  # Buffer list to store intermediate values\n",
        "  zero_shot_for_summary = dict(zip(emotion_list, initial_probs))\n",
        "\n",
        "\n",
        "  # Loop over the blocks in the summary\n",
        "  for summary_block in summary:\n",
        "\n",
        "    #print(wrapper.fill(''.join(summary_block)))\n",
        "    #print('\\n')\n",
        "\n",
        "    # Perform Zero Shot Classification\n",
        "\n",
        "    # pose sequence as a NLI premise and label (politics) as a hypothesis\n",
        "    premise = summary_block\n",
        "\n",
        "    for label in labels:\n",
        "\n",
        "      hypothesis = f'This text is about {label}.'\n",
        "\n",
        "      # run through model pre-trained on MNLI\n",
        "      x = tokenizer.encode(premise, hypothesis, return_tensors='pt',\n",
        "                              max_length=tokenizer.max_len,\n",
        "                              truncation_strategy='only_first')\n",
        "      x = x.to(device)\n",
        "      logits = model(x)[0]\n",
        "\n",
        "      # We throw away \"neutral\" (dim 1) and take the probability of\n",
        "      # \"Entailment\" as the probability of the label being true \n",
        "      entail_contradiction_logits = logits[:,[0,2]]\n",
        "      probs = entail_contradiction_logits.softmax(1)\n",
        "      prob_label_is_true = probs[:,1]\n",
        "\n",
        "      # Update the initial probabilities in the dict for the label\n",
        "      zero_shot_for_summary[label] = prob_label_is_true.item() \n",
        "      \n",
        "      # Accumulate the initial probabilities in the dict for the label\n",
        "      zero_shot_for_summary_averaged[label] += prob_label_is_true.item() \n",
        "\n",
        "\n",
        "      #print(f'Probability the text belongs to {label} is: {prob_label_is_true.item():0.2f}%')\n",
        "\n",
        "    # Find the dominant theme in the block (cummulative)\n",
        "    keymax = max(zero_shot_for_summary_averaged, key=zero_shot_for_summary_averaged.get) \n",
        "\n",
        "    # Update the hard dominance dict \n",
        "    zero_shot_for_summary_hard_dominance[keymax] += 1\n",
        "\n",
        "    # Find the dominant theme in the block (non-cummulative)\n",
        "    keymax = max(zero_shot_for_summary, key=zero_shot_for_summary.get) \n",
        "\n",
        "    # Update the soft dominance dict \n",
        "    zero_shot_for_summary_soft_dominance[keymax] += 1\n",
        "  \n",
        "  \n",
        "  for label in labels:\n",
        "\n",
        "    # Average out the probabilities after each block in the summary has been assigned a probability\n",
        "    zero_shot_for_summary_averaged[label] /= num_blocks\n",
        "\n",
        "    # Calculate the dominance percentage \n",
        "    zero_shot_for_summary_soft_dominance[label] /= num_blocks\n",
        "\n",
        "    # Calculate the dominance percentage \n",
        "    zero_shot_for_summary_hard_dominance[label] /= num_blocks\n",
        "\n",
        "\n",
        "  # Filter out all labels are zeroes for soft dominance\n",
        "  zero_shot_for_summary_soft_dominance = {key:val for key, val in zero_shot_for_summary_soft_dominance.items() if val > 0.0}\n",
        "\n",
        "  # Filter out all labels are zeroes for hard dominance\n",
        "  zero_shot_for_summary_hard_dominance = {key:val for key, val in zero_shot_for_summary_hard_dominance.items() if val > 0.0} \n",
        "  \n",
        "  # Filter out all the labels that are less than 25% for averaged  \n",
        "  #zero_shot_for_summary_averaged = {key:val for key, val in zero_shot_for_summary_averaged.items() if val >= 0.15}\n",
        "\n",
        "\n",
        "  # Print out the dict of classification probabilities\n",
        "  #print(zero_shot_for_summary)\n",
        "  #print(dominance_frequency)\n",
        "  #print('\\n')\n",
        "  #print('-' * 50)\n",
        "\n",
        "  # Append the results for one summary to the global list\n",
        "  #print(zero_shot_for_summary_averaged)\n",
        "  #print(zero_shot_for_summary_soft_dominance)\n",
        "  #print(zero_shot_for_summary_hard_dominance)\n",
        "  zero_shot_averaged.append(zero_shot_for_summary_averaged)\n",
        "  zero_shot_soft_dominance.append(zero_shot_for_summary_soft_dominance)\n",
        "  zero_shot_hard_dominance.append(zero_shot_for_summary_hard_dominance)\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yU_7_smL8qmO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Append the zero shot classification results to the existing dataframe and save it\n",
        "\n",
        "# Load\n",
        "df = pd.read_pickle('/content/db_633_f.pickle')\n",
        "df.head()\n",
        "\n",
        "# Apoend\n",
        "df['Zero Shot Classification (Averaged)'] = zero_shot_averaged\n",
        "df['Zero Shot Classification (Soft Dominance)'] = zero_shot_soft_dominance\n",
        "df['Zero Shot Classification (Hard Dominance)'] = zero_shot_hard_dominance\n",
        "df.head()\n",
        "\n",
        "# Save\n",
        "df.to_pickle('/content/db_633_zero_shot_f.pickle')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7KDekZv4Vtl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-G0-yLdIJpX",
        "colab_type": "text"
      },
      "source": [
        "### **2.  Shortlist**\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "First, we take the user input and then we perform computations of two tracks:\n",
        "\n",
        "**Track 1** aims to extract the rich semantic information from the title of the videos. \n",
        "\n",
        "**Track 2** aims to extract the semantic information in the content of the videos itself."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6znJYm4z5zZX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read dataframe \n",
        "df = pd.read_pickle('/content/db_633_zero_shot_f.pickle')\n",
        "\n",
        "# Retrieve soem columns of the DataFrame\n",
        "zero_shot_averaged = df['Zero Shot Classification (Averaged)'].tolist()\n",
        "zero_shot_soft_dominance = df['Zero Shot Classification (Soft Dominance)'].tolist()\n",
        "zero_shot_hard_dominance = df['Zero Shot Classification (Hard Dominance)'].tolist()\n",
        "video_ids = df['Video ID'].tolist()\n",
        "video_titles = df['Video Title'].tolist()\n",
        "transcripts = df['Transcript Blocks'].tolist()\n",
        "summaries = df['Summary Blocks'].tolist()\n",
        "\n",
        "# Display the DataFrame\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8DUdaLrqGlc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Some basic processing to combine all the zero shot classification methods into a single list\n",
        "\n",
        "# Filter zero_shot_averaged list\n",
        "filtered_zero_shot_averaged = list()\n",
        "for zero_shots in zero_shot_averaged:\n",
        "  filtered_probs_dict = {key:val for key, val in zero_shots.items() if val >= 0.25}\n",
        "  filtered_zero_shot_averaged.append(filtered_probs_dict)\n",
        "\n",
        "# Combine all\n",
        "zero_shot = list()\n",
        "for index in range(len(zero_shot_averaged)):\n",
        "  zero_shot.append(list(set(filtered_zero_shot_averaged[index].keys()).union(set(zero_shot_soft_dominance[index].keys()).union(set(zero_shot_hard_dominance[index].keys())))))\n",
        "\n",
        "# Ensure the length of the final list is equal to the number of transcripts \n",
        "assert len(zero_shot)==len(zero_shot_averaged)\n",
        "assert len(zero_shot)==len(zero_shot_soft_dominance)\n",
        "assert len(zero_shot)==len(zero_shot_hard_dominance)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PP11kvtTnhk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We'll define the themes we'll be using to classify the transcripts on\n",
        "# These themes reflect the names of the playlists we have scrapped for the transcripts\n",
        "\n",
        "themes = '''\n",
        "\n",
        "love and relationships\n",
        "addiction and compulsiveness\n",
        "unraveling death\n",
        "karma\n",
        "education\n",
        "parenting\n",
        "suffering\n",
        "stress\n",
        "time management\n",
        "existence of god\n",
        "living happily\n",
        "health\n",
        "success\n",
        "depression\n",
        "marriage\n",
        "sleep and restfulness\n",
        "peace\n",
        "virus\n",
        "\n",
        "'''\n",
        "\n",
        "# Process themes and define a dict to map from the index number to the theme\n",
        "themes = themes.strip().split('\\n')\n",
        "emotion_list = themes\n",
        "emotion_ids = list(range(1, len(emotion_list)+1))\n",
        "emotion_ids_to_emotions = dict(zip(emotion_ids, emotion_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aqEu-mw0QoS",
        "colab_type": "text"
      },
      "source": [
        "#### **Just some examples!**\n",
        "\n",
        "---\n",
        "\n",
        "Try any of these or write your own!\n",
        "\n",
        "To try:\n",
        "\n",
        "1. Copy the string and enter it on the next cell! \n",
        "\n",
        "2. Done!\n",
        "\n",
        "(Click below to reveal)\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQ5vKmx1Q6ad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############## EXAMPLES #################\n",
        "\n",
        "s1 = \"I just had a breakup with my girlfriend. She decided to part ways but i am unable to accept or process this. I feel lost all the time and cannot focus at work or anywhere else. I cannot move on. At night, her memory keeps me up. in the morning too, and even at work, I see her face. I cannot get her out of my mind. I don't know what to do.\"\n",
        "s2 = \"After losing my job, there is a lot of pressure on me. I keep having negative thoughts all the time. I feel like I am worthless. I feel myself slipping to depression. I don't know what to do.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ah0HuO6T1GKH",
        "colab_type": "text"
      },
      "source": [
        "#### **Your input goes here!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmTAncZoK9Ir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Take Input from user\n",
        "inputs_descrption = input('Please feel free to describe what you are going through: ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVey9PX6T8sD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clean input\n",
        "inputs_descrption = re.sub(\"(\\.\\.+)\", '', inputs_descrption)\n",
        "inputs_descrption = re.sub('\\s+', ' ', inputs_descrption)\n",
        "inputs_descrption = inputs_descrption.lower()\n",
        "\n",
        "# Display the inputs given by the user\n",
        "print('Your inputs were: \\n')\n",
        "print(f'{inputs_descrption}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meNPG7tSTDVd",
        "colab_type": "text"
      },
      "source": [
        "#### **Track 1 : Matching Video Titles to User Input**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hj-9-LxQrHW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First, preprocess all titles to remove anything that does not provide useful semantic informaiton\n",
        "\n",
        "def clean_sentence(sentence):\n",
        "    stop_words = ['Sadhguru', 'IST', 'Unplug', 'unplug', '@', 'everyday']\n",
        "    tokens = sentence.split()\n",
        "    tokens_filtered= [word for word in tokens if not word in stop_words]\n",
        "    filtered_sentence = ' '.join(tokens_filtered)\n",
        "\n",
        "    return filtered_sentence\n",
        "\n",
        "\n",
        "def is_valid_date(date_str):\n",
        "    try:\n",
        "        parser.parse(date_str)\n",
        "        return True\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "new_list = [' '.join([w for w in line.split() if not is_valid_date(w)]) for line in video_titles]\n",
        "new_list = [re.sub('[^\\sA-Za-z0-9]+', '', mystring) for mystring in new_list]\n",
        "new_list = [re.sub('\\s+', ' ', mystring) for mystring in new_list]\n",
        "new_list = [clean_sentence(mystring) for mystring in new_list]\n",
        "titles = [mystring.replace('Sadhguru', '').replace('Unplug', '').replace('IST', '').replace('@', '').replace('With in Challenging Times', '').replace('with in Challenging Times', '') for mystring in new_list]\n",
        "titles = [mystring.replace('', 'xxx deleted xxx') if mystring=='' else mystring for mystring in titles]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsFuMOzXLG3j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "9c2343c1-c01e-4043-9655-9f79ce1590e5"
      },
      "source": [
        "# Load model to get embeddings from sentences\n",
        "model = SentenceTransformer('roberta-large-nli-stsb-mean-tokens', device=0)\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.31G/1.31G [00:27<00:00, 47.2MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLw2bC7ZR9wj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "ef4f71dd-9f5f-43da-ccdb-a4b7040c6226"
      },
      "source": [
        "# Get user embeddings by passing the user input to the loaded model\n",
        "user_text = inputs_descrption\n",
        "user_sent_text = nltk.sent_tokenize(user_text)\n",
        "user_sent_text_embeddings = model.encode(user_sent_text)\n",
        "\n",
        "# Average the embeddings\n",
        "user_sent_text_embeddings = sum(user_sent_text_embeddings) / len(user_sent_text)\n",
        "user_sent_text_embeddings = np.reshape(user_sent_text_embeddings, (1, user_sent_text_embeddings.shape[0]))\n",
        "\n",
        "# Get title embeddings by passing all video titles to the loaded model\n",
        "title_embeddings = np.asarray(model.encode(titles))\n",
        "\n",
        "# Find the similarity of each title embedding with the user embedding using Cosine similarity\n",
        "similarities = cosine_similarity(user_sent_text_embeddings, title_embeddings)\n",
        "similarities = list(np.reshape(similarities, (similarities.shape[1])))\n",
        "\n",
        "# Get indices of top 20 videos\n",
        "top_20_from_video_titles = sorted(range(len(similarities)), key=lambda i: similarities[i])[-20:]\n",
        "\n",
        "# Print titles of the selected 20 videos\n",
        "for video_title_index in top_20_from_video_titles:\n",
        "  print(titles[video_title_index])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Troubled by Fear Just Change Your Channel\n",
            "The Desire For Everything Understanding The Human Predicament\n",
            "Depression Stop The Suicide In Installments\n",
            "Dont Let Fear of Suffering Limit Your Possibility\n",
            "Why Is Breaking Up So Painful\n",
            "How Do I Deal With Unfulfilled Expectations\n",
            "Missing Life is a Tragedy\n",
            "Coping With The Emotional Turmoil In A Pandemic \n",
            "Sick with Exam Fear This Will Help\n",
            "Heaven is a Lousy Place \n",
            "Becoming Utterly Ignorant\n",
            "Insight Into Depression\n",
            "What is The Worst Ailment You Can Get \n",
            "Is Suffering Inevitable\n",
            "The End of Suffering\n",
            "Why Misery\n",
            "Why Am I Stressed on Stress\n",
            "on The Source of All Suffering\n",
            "on Fear of Failure\n",
            "The Source of Human Misery\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1aVymQa1mdD",
        "colab_type": "text"
      },
      "source": [
        "##### **Question: Is averaging the embeddings a good representation of all the sentences in a query or paragraph?**\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "Yes, it does seem to be a fair represenation of the overall sentiment in the sentences! This can be shown by the similarity matrix between the average of all sentence embeddings and the embeddings of the individual sentence! \n",
        "\n",
        "The similarity matrix shows that most of the individual sentence embedding matches with more than 50% with the average embedding thus strenghtening the assumption that the average embedding is indeed a fair represention of the overall sentiment in the sentences! \n",
        "\n",
        "The sentences that match less than 50% are usually bland sentences like \"I don't know\" etc\n",
        "\n",
        "(Click below to see the code)\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjkVLeV52KqM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "040879f2-fb71-40a3-9d1b-d72cf4543ef3"
      },
      "source": [
        "# Get embeddings of individual sentences\n",
        "user_text = inputs_descrption\n",
        "user_sent_text = nltk.sent_tokenize(user_text)\n",
        "user_sent_text_embeddings = np.asarray(model.encode(user_sent_text))\n",
        "\n",
        "# Get average embeddings of all sentences\n",
        "user_text = inputs_descrption\n",
        "user_sent_text = nltk.sent_tokenize(user_text)\n",
        "user_sent_text_embeddings_avg = model.encode(user_sent_text)\n",
        "user_sent_text_embeddings_avg = sum(user_sent_text_embeddings_avg) / len(user_sent_text)\n",
        "user_sent_text_embeddings_avg = np.reshape(user_sent_text_embeddings_avg, (1, user_sent_text_embeddings_avg.shape[0]))\n",
        "\n",
        "# Finally, get similarity matrix\n",
        "cosine_similarity(user_sent_text_embeddings, user_sent_text_embeddings_avg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.531698  ],\n",
              "       [0.6648342 ],\n",
              "       [0.6563994 ],\n",
              "       [0.68624353],\n",
              "       [0.48793417],\n",
              "       [0.41167915],\n",
              "       [0.7173095 ],\n",
              "       [0.6379081 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxGKRvggS1hj",
        "colab_type": "text"
      },
      "source": [
        "#### **Track 2 : Extracting Tags from User Input, Filtering Videos using the Zero Shot Classified Summaries, and Matching the Filtered Videos to the Semantic Content in those Videos**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9xTeyMNSDYT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214,
          "referenced_widgets": [
            "8904840bbc8745dc844f7e5228f14908",
            "443c299d714a478f9a8a0eff61b6ace8",
            "8cbe6bf778e345a8b3a2081f0ed5e04e",
            "4cd69f7a8d4f491d910f492eada08fa7",
            "c3c11b0f0afa4d77a3e1ce35899b02ad",
            "ee5898af3c18447fb1d7101924492fdb",
            "1749e472c62a4aa7a231577df540809c",
            "4c6d94e4fd7c4b8daa4bb72411ca5c7e",
            "e2cb425e759841408b368a9f0daecfd9",
            "968ec17e333a406b8174bb102eb071f7",
            "f9dd291a0581462685be5bbc4d1bc9b8",
            "47e3683f8cdf4133bdcd2323038543db",
            "2c1bd31615ad45dd95a6b809827d1d50",
            "4da23c3a3a2e46a598fe16cc0a775856",
            "8d725720465a4a82a93269561bc12c5b",
            "ec455b321c104e15b5bb7fa427cd1574",
            "2bc94607eddd4e4ead266b82b00a8b40",
            "49bdeb597505432bb79d8eac9bc42846",
            "8c1b664efaf9472d837e9a9197aadf34",
            "f1296e3c66a14eb3a6137f693cea7357",
            "c0f1e8a26a6a4e64822cea4bfde86d98",
            "89a95780a48d4e12a92be4529fd58b09",
            "36b46e64a76b4e0488e2bf71fd260d79",
            "800a0d1b5c5841209c2c6352ba887296",
            "eff8e617e29f4a12af0d87577fa39b1b",
            "3a8fb47dd60348f08cc750c83bf09ab3",
            "c5ed342261f64a96a6ab8bc2ad6846af",
            "685c60f822c14fa59f07df64a4b46553",
            "4200c71e62214ad59faeac3e51e338e6",
            "8050f29d25e74a399836813ad9da464c",
            "e331ca57f7354eb799ce87d107f7fb79",
            "bde0ecfc0cb6472db0d8a8ebba246894"
          ]
        },
        "outputId": "7139d468-e516-41e5-8b0c-3d726b00fdcb"
      },
      "source": [
        "# Load model for zero shot classification\n",
        "# Set up Bart for tag extraction\n",
        "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-mnli')\n",
        "model2 = BartForSequenceClassification.from_pretrained('facebook/bart-large-mnli').to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8904840bbc8745dc844f7e5228f14908",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e2cb425e759841408b368a9f0daecfd9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2bc94607eddd4e4ead266b82b00a8b40",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=908.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eff8e617e29f4a12af0d87577fa39b1b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1629486723.0, style=ProgressStyle(descrâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7TuXpIHY2wb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "822596b2-09ba-4842-f532-695df80362f1"
      },
      "source": [
        "# Now pick up tags from the user input\n",
        "\n",
        "initial_probs = [0.00] * len(emotion_list)\n",
        "initial_dominance = [0] * len(emotion_list)\n",
        "num_sents = len(user_sent_text)\n",
        "labels = emotion_list\n",
        "\n",
        "# Define local list (one summary) for Averaged method\n",
        "zero_shot_for_user_text_averaged = dict(zip(emotion_list, initial_probs))\n",
        "\n",
        "# Define local list (one summary) for Hard Dominance method\n",
        "zero_shot_for_user_text_hard_dominance = dict(zip(emotion_list, initial_dominance))\n",
        "\n",
        "# Define local list (one summary) for Soft Dominance method\n",
        "zero_shot_for_user_text_soft_dominance = dict(zip(emotion_list, initial_dominance))\n",
        "\n",
        "# Buffer list to store intermediate values\n",
        "zero_shot_for_user_text = dict(zip(emotion_list, initial_probs))\n",
        "\n",
        "# Loop over all sentences in the user input\n",
        "for user_text in tqdm(user_sent_text):\n",
        "\n",
        "    # pose sequence as a NLI premise and label (politics) as a hypothesis\n",
        "    premise = user_text\n",
        "\n",
        "    for label in labels:\n",
        "\n",
        "      hypothesis = f'This text is about {label}.'\n",
        "\n",
        "      # run through model pre-trained on MNLI\n",
        "      x = tokenizer.encode(premise, hypothesis, return_tensors='pt',\n",
        "                              max_length=tokenizer.max_len,\n",
        "                              truncation_strategy='only_first')\n",
        "      x = x.to(device)\n",
        "      logits = model2(x)[0]\n",
        "\n",
        "      # We throw away \"neutral\" (dim 1) and take the probability of\n",
        "      # \"Entailment\" as the probability of the label being true \n",
        "      entail_contradiction_logits = logits[:,[0,2]]\n",
        "      probs = entail_contradiction_logits.softmax(1)\n",
        "      prob_label_is_true = probs[:,1]\n",
        "\n",
        "      # Update the initial probabilities in the dict for the label\n",
        "      zero_shot_for_user_text[label] = prob_label_is_true.item() \n",
        "      \n",
        "      # Accumulate the initial probabilities in the dict for the label\n",
        "      zero_shot_for_user_text_averaged[label] += prob_label_is_true.item() \n",
        "\n",
        "      #print(f'Probability the text belongs to {label} is: {prob_label_is_true.item():0.2f}%')\n",
        "\n",
        "    # Find the dominant theme in the block (cummulative)\n",
        "    keymax = max(zero_shot_for_user_text_averaged, key=zero_shot_for_user_text_averaged.get) \n",
        "\n",
        "    # Update the hard dominance dict \n",
        "    zero_shot_for_user_text_hard_dominance[keymax] += 1\n",
        "\n",
        "    # Find the dominant theme in the block (non-cummulative)\n",
        "    keymax = max(zero_shot_for_user_text, key=zero_shot_for_user_text.get) \n",
        "\n",
        "    # Update the soft dominance dict \n",
        "    zero_shot_for_user_text_soft_dominance[keymax] += 1\n",
        "  \n",
        "  \n",
        "for label in labels:\n",
        "\n",
        "  # Average out the probabilities after each block in the summary has been assigned a probability\n",
        "  zero_shot_for_user_text_averaged[label] /= num_sents\n",
        "\n",
        "  # Calculate the dominance percentage \n",
        "  zero_shot_for_user_text_soft_dominance[label] /= num_sents\n",
        "\n",
        "  # Calculate the dominance percentage \n",
        "  zero_shot_for_user_text_hard_dominance[label] /= num_sents\n",
        "\n",
        "\n",
        "# Filter out all the labels that are less than 25% for averaged\n",
        "zero_shot_for_user_text_averaged = {key:val for key, val in zero_shot_for_user_text_averaged.items() if val >= 0.25}\n",
        "\n",
        "# Filter out all labels are zeroes for soft dominance\n",
        "zero_shot_for_user_text_soft_dominance = {key:val for key, val in zero_shot_for_user_text_soft_dominance.items() if val > 0.0}\n",
        "\n",
        "# Filter out all labels are zeroes for hard dominance\n",
        "zero_shot_for_user_text_hard_dominance = {key:val for key, val in zero_shot_for_user_text_hard_dominance.items() if val > 0.0} "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:03<00:00,  1.35it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY0OQe5vaZjm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "08877627-62fd-47ca-d5be-aadc7a3c3f2d"
      },
      "source": [
        "# Print the extracted tags using different methods\n",
        "pprint(zero_shot_for_user_text_soft_dominance)\n",
        "pprint(zero_shot_for_user_text_hard_dominance)\n",
        "pprint(zero_shot_for_user_text_averaged)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'stress': 0.2, 'suffering': 0.8}\n",
            "{'stress': 0.6, 'suffering': 0.4}\n",
            "{'depression': 0.5996770307421684,\n",
            " 'stress': 0.7527786880731583,\n",
            " 'suffering': 0.9185027122497559}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBRWqFw0VIwH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shortlist videos based on extracted tags from Input \n",
        "user_tags = list(set(zero_shot_for_user_text_averaged.keys()).union(set(zero_shot_for_user_text_soft_dominance.keys()).union(set(zero_shot_for_user_text_hard_dominance.keys()))))\n",
        "labels = set(user_tags)\n",
        "\n",
        "# Get all combinations of the input\n",
        "from itertools import chain, combinations\n",
        "\n",
        "def powerset(iterable):\n",
        "    \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
        "    s = list(iterable)\n",
        "    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))\n",
        "\n",
        "combination_of_user_tags = list(powerset(user_tags))\n",
        "combination_of_user_tags = [list(user_tag) for user_tag in combination_of_user_tags if len(user_tag)>1]\n",
        "\n",
        "# Get matches for all the combination of tags\n",
        "matches = list()\n",
        "for user_tag in combination_of_user_tags:\n",
        "  for idx, entry in enumerate(zero_shot):\n",
        "    if set(user_tag).issubset(set(entry)):\n",
        "      matches.append(idx)\n",
        "\n",
        "# Keep only the unique matches\n",
        "matches = set(matches)\n",
        "\n",
        "# Print them\n",
        "#for match in matches:\n",
        "  #print(match)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6gaX4pZWpDR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "144b8760-51de-4b1d-8669-203d2a04e85b"
      },
      "source": [
        "# Filter Videos using NLP\n",
        "\n",
        "# Get user embeddings by passing the user input to the loaded model\n",
        "user_text = inputs_descrption\n",
        "user_sent_text = nltk.sent_tokenize(user_text)\n",
        "user_sent_text_embeddings = model.encode(user_sent_text)\n",
        "\n",
        "# Average the embeddings\n",
        "user_sent_text_embeddings = sum(user_sent_text_embeddings) / len(user_sent_text)\n",
        "user_sent_text_embeddings = np.reshape(user_sent_text_embeddings, (1, user_sent_text_embeddings.shape[0]))\n",
        "\n",
        "sim_mats = list()\n",
        "sim_scores = list()\n",
        "non_zero_percentages = list()\n",
        "total_doms = list()\n",
        "nzall = list()\n",
        "tssall = list()\n",
        "\n",
        "matched_blocks_all = list()\n",
        "\n",
        "for match in tqdm(matches):\n",
        "\n",
        "  summary = summaries[match]\n",
        "  non_zero_percentage = 0\n",
        "  sim_scores_loc = list()\n",
        "  matched_blocks = list()\n",
        "\n",
        "  doms = list()\n",
        "\n",
        "  for idx, block in enumerate(summary):\n",
        "\n",
        "    #block_text = ' '.join(block)\n",
        "    block_sent_text = nltk.sent_tokenize(block)\n",
        "    #pprint(block_sent_text)\n",
        "    #print('\\n')\n",
        "\n",
        "    block_sent_text_embeddings = model.encode(block_sent_text)\n",
        "    block_sent_text_embeddings = sum(block_sent_text_embeddings) / len(block_sent_text_embeddings)\n",
        "    block_sent_text_embeddings = np.reshape(block_sent_text_embeddings, (1, block_sent_text_embeddings.shape[0]))\n",
        "    similarity = cosine_similarity(user_sent_text_embeddings, block_sent_text_embeddings)\n",
        "\n",
        "    sim_scores_loc.append(similarity)\n",
        "\n",
        "    if similarity>=0.50:\n",
        "      non_zero_percentage += 1\n",
        "\n",
        "    #pprint(sim_mat)\n",
        "    #print('\\n')\n",
        "\n",
        "    #pprint(sum_row)\n",
        "    #print('/n')\n",
        "\n",
        "    #pprint(sum_total)\n",
        "    #print('/n')\n",
        "\n",
        "\n",
        "  #non_zero_percentage = len(matched_blocks) / len(transcript)\n",
        "  #non_zero_percentage = (sum([d for d in doms if d!=0])/len(doms)) * 100\n",
        "  #non_zero_percentages.append(non_zero_percentage)\n",
        "  #total_doms.append(doms)\n",
        "  matched_blocks_all.append(matched_blocks)\n",
        "  sim_scores.append(sum(sim_scores_loc)/len(sim_scores_loc))\n",
        "  non_zero_percentages.append(non_zero_percentage/len(summary))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 186/186 [01:36<00:00,  1.94it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8etSoDSWuDW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e7731855-5492-4952-e581-9bcd4ad917d6"
      },
      "source": [
        "# Get indices of top 20 maximum matches\n",
        "indices = sorted(range(len(sim_scores)), key=lambda i: sim_scores[i])[-50:]\n",
        "indices2 = sorted(range(len(non_zero_percentages)), key=lambda i: non_zero_percentages[i])[-50:]\n",
        "matches_from_indices = [match for idx, match in enumerate(matches) if idx in indices]\n",
        "matches_from_indices2 = [match for idx, match in enumerate(matches) if idx in indices2]\n",
        "\n",
        "\n",
        "# Print titles of the selected 20 videos\n",
        "for top in matches_from_indices:\n",
        "  print(video_titles[top])\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "# Print titles of the selected 20 videos\n",
        "for top in matches_from_indices2:\n",
        "  print(video_titles[top])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "How to Deal with Relationships? | Sadhguru\n",
            "How to Deal with an Exploitative Spouse? Sadhguru\n",
            "How Do You Accept People You Don't Like? Sadhguru\n",
            "What Is True Friendship? â€“ Sadhguru\n",
            "Is it Ok to be Jealous of a Friendâ€™s Success? - Sadhguru\n",
            "Why Do We Seek Success in Relationships? - Sadhguru\n",
            "â€‹Humanity, Yes! Morality, No! | Sadhguru\n",
            "Why Good People Wonâ€™t Get Anywhere | Sadhguru\n",
            "Troubled by Fear? Just Change Your Channel! - Sadhguru\n",
            "To Make a Journey, Donâ€™t Change Directions | Sadhguru\n",
            "Resisting Change is Resisting Life | Sadhguru\n",
            "Is it true pregnant women should not do Aum Kar? Sadhguru\n",
            "Why Would One Take Their Own Life? Sadhguru - With Sadhguru in Challenging Times - 14th Jun\n",
            "Bliss Beyond Intoxication | Sadhguru\n",
            "Sadhguru on Why Being a Soldier Is a Big Deal\n",
            "Why are you suffering the Lockdown - With Sadhguru in Challenging Times - 30 Mar\n",
            "Just a Brief Life | Sadhguru\n",
            "Untangling the Knots of Life | Sadhguru\n",
            "Stop Creating | Sadhguru\n",
            "Ending Fear-Based Education - Sadhguru\n",
            "Why Do Parents Worry So Much About Their Children? â€“ Sadhguru\n",
            "Are Dreams and Life just an illusion - Sadhguru\n",
            "Intense and Relaxed | Sadhguru\n",
            "Step One, Balance! | Sadhguru\n",
            "Missing Life is a Tragedy | Sadhguru\n",
            "Ordinary to Extra-ordinary | Suhel Seth with Sadhguru\n",
            "Forget Facebook, Get a Big \"LIKE\" From the Universe! | Sadhguru\n",
            "How to Deal with Attachment? | Sadhguru\n",
            "An Antidote to Stress | Sadhguru\n",
            "How Do You Overcome Fear? | Sadhguru\n",
            "What is the Purpose of Life? - Sadhguru\n",
            "Living Being or Psychological Case: Whatâ€™s Your Choice? | Sadhguru\n",
            "Becoming Utterly Ignorant | Sadhguru\n",
            "Hyderabad Bomb Blast & Violence - Sadhguru Speaks (Part 1)\n",
            "What is Devotion? | Sadhguru\n",
            "A Good Day for the Cosmos! - Sadhguru\n",
            "Survival is Not Enough | Sadhguru\n",
            "Are You Looking for Solace or a Solution? | Sadhguru\n",
            "Sadhguru and Shekhar Kapur on Stress\n",
            "Going Beyond Stress | Sadhguru\n",
            "Being Human is a Possibility, Not a Limitation | Sadhguru\n",
            "Have You Experienced God? | Sadhguru\n",
            "Why Wait? | Sadhguru\n",
            "â€‹Hero or Zero? What Are You? | Sadhguru\n",
            "Asleep, or Just Pretending? | Sadhguru\n",
            "Why Build Spiritual Spaces Instead of Hospitals? | Sadhguru\n",
            "How to Achieve Wellbeing? | Sadhguru\n",
            "Donâ€™t Let Fear of Suffering Limit Your Possibility - Sadhguru\n",
            "â€‹â€‹\"90% of my life...\" | Sadhguru\n",
            "Time for a Life Audit | Sadhguru\n",
            "\n",
            "\n",
            "How to Deal with an Exploitative Spouse? Sadhguru\n",
            "Stop Digging Into The Past - Sadhguru\n",
            "How Do You Accept People You Don't Like? Sadhguru\n",
            "What Is True Friendship? â€“ Sadhguru\n",
            "Is it Ok to be Jealous of a Friendâ€™s Success? - Sadhguru\n",
            "Why Do We Seek Success in Relationships? - Sadhguru\n",
            "â€‹Humanity, Yes! Morality, No! | Sadhguru\n",
            "Why Good People Wonâ€™t Get Anywhere | Sadhguru\n",
            "Troubled by Fear? Just Change Your Channel! - Sadhguru\n",
            "Resisting Change is Resisting Life | Sadhguru\n",
            "Becoming Sensitive to Life | Sadhguru\n",
            "What is the Worst That Can Happen in This COVID Era? - With Sadhguru in Challenging Times - 28th Jun\n",
            "Why Would One Take Their Own Life? Sadhguru - With Sadhguru in Challenging Times - 14th Jun\n",
            "Involvement, Not Law, is Solution for Womenâ€™s Welfare\n",
            "Does Fear Bring Out the Best in You? - With Sadhguru in Challenging Times - 25 Apr\n",
            "Bliss Beyond Intoxication | Sadhguru\n",
            "Can This Disruption Become a Possibility? - With Sadhguru in Challenging Times - 12 Apr\n",
            "Who is Right - Patanjali or Krishna? - With Sadhguru in Challenging Times - 10 Apr\n",
            "The Rules of Life and Death | Sadhguru\n",
            "Why are you suffering the Lockdown - With Sadhguru in Challenging Times - 30 Mar\n",
            "Just a Brief Life | Sadhguru\n",
            "Coping With The Emotional Turmoil In A Pandemic - With Sadhguru in Challenging Times - 28 Mar\n",
            "How to Empower Yourself to Handle Corona - With Sadhguru in Challenging Times - 24 Mar\n",
            "Stop Creating | Sadhguru\n",
            "Memory & Imagination - Possibilities Not Problems | Sadhguru\n",
            "An Ideal Education - Part 1, Sir Ken Robinson with Sadhguru\n",
            "Ending Fear-Based Education - Sadhguru\n",
            "Why Do Parents Worry So Much About Their Children? â€“ Sadhguru\n",
            "How Sex & Violence on TV Is Affecting Our Children â€“ Sadhguru on Sacred Games\n",
            "Why Must Handicapped Children Suffer? | Sadhguru\n",
            "Is Cloning Okay? | Sadhguru\n",
            "The Doorway of Memory | Sadhguru\n",
            "Missing Life is a Tragedy | Sadhguru\n",
            "Ordinary to Extra-ordinary | Suhel Seth with Sadhguru\n",
            "An Antidote to Stress | Sadhguru\n",
            "How Do You Overcome Fear? | Sadhguru\n",
            "Living Being or Psychological Case: Whatâ€™s Your Choice? | Sadhguru\n",
            "Hyderabad Bomb Blast & Violence - Sadhguru Speaks (Part 1)\n",
            "How to Dissolve the Drama of Life? | Sadhguru\n",
            "A Good Day for the Cosmos! - Sadhguru\n",
            "Are You Looking for Solace or a Solution? | Sadhguru\n",
            "Sadhguru and Shekhar Kapur on Stress\n",
            "Going Beyond Stress | Sadhguru\n",
            "How to Control Stress - Sadhguru and Arianna Huffington\n",
            "Being Human is a Possibility, Not a Limitation | Sadhguru\n",
            "Why Wait? | Sadhguru\n",
            "Why Build Spiritual Spaces Instead of Hospitals? | Sadhguru\n",
            "Why Doesn't Hard Work Bring Me Success? - Sadhguru Answers\n",
            "Donâ€™t Let Fear of Suffering Limit Your Possibility - Sadhguru\n",
            "â€‹â€‹\"90% of my life...\" | Sadhguru\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQlP7A_YXaR4",
        "colab_type": "text"
      },
      "source": [
        "### **3. Recommendation: Intersection of Track 1 (Video Title Semantics) and Track 2 (Video Content Semantics)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHvDkH-gJcTi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Intersection of track1 and track2 \n",
        "intersection = list(set(top_20_from_video_titles).intersection(matches_from_indices2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trvLufaNXSNv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "3f1460d3-8d68-48a2-c3ff-90e5815c9069"
      },
      "source": [
        "# Print titles of the intersection\n",
        "print('The recommendations found are as follows: \\n')\n",
        "\n",
        "for top in intersection:\n",
        "  print(video_titles[top])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The recommendations found are as follows: \n",
            "\n",
            "Coping With The Emotional Turmoil In A Pandemic - With Sadhguru in Challenging Times - 28 Mar\n",
            "Donâ€™t Let Fear of Suffering Limit Your Possibility - Sadhguru\n",
            "Missing Life is a Tragedy | Sadhguru\n",
            "Troubled by Fear? Just Change Your Channel! - Sadhguru\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmgcgQvgX0HV",
        "colab_type": "text"
      },
      "source": [
        "### **4. Smart Snippets (Targetted Recommendations)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTobNKu3kB4a",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "om-T6EfnYIz-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}